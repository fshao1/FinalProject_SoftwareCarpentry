{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the TODO_Directory_and_Folder_Name\n",
    "# Change the directory to the GTSRB folder that contains the dataset\n",
    "cd '/content/drive/My Drive/TODO_Directory_and_Folder_Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "class TrainDataset():\n",
    "    '''\n",
    "    Training Dataset class for pytorch dataloader\n",
    "    '''\n",
    "    def __init__(self, rootpath, transforms=None):\n",
    "        '''\n",
    "        Initiate class variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rootpath : str\n",
    "            The directory of the training dataset\n",
    "        transforms : <class 'torchvision.transforms.transforms.Compose'>\n",
    "            Transforms that will be applied to the images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        self.rootpath = rootpath\n",
    "        self.images = []  # images\n",
    "        self.labels = []  # corresponding labels\n",
    "        self.transforms = transforms\n",
    "        for c in range(0, 43):\n",
    "            # subdirectory for class\n",
    "            prefix = self.rootpath + '/' + format(c, '05d') + '/'\n",
    "            # annotations file\n",
    "            gtFile = open(prefix + 'GT-' + format(c, '05d') + '.csv')\n",
    "            # csv parser for annotations file\n",
    "            gtReader = csv.reader(gtFile, delimiter=';')\n",
    "            # skip header\n",
    "            next(gtReader)\n",
    "            # loop over all images in current annotations file\n",
    "            for row in gtReader:\n",
    "                image = Image.open(prefix + row[0], 'r')\n",
    "                image_arr = np.array(image)\n",
    "                image.close()\n",
    "                image = Image.fromarray(image_arr)\n",
    "                # the 1th column is the filename\n",
    "                self.images.append(image)\n",
    "                # the 8th column is the label\n",
    "                self.labels.append(int(row[7]))\n",
    "            gtFile.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Length of the class or dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Length of the dataset\n",
    "\n",
    "        '''\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Used for list indexing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            indexs for the list\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : PIL file\n",
    "            Returns PIL file for later transformation\n",
    "        label : torch.tensor\n",
    "            Returns torch.tensor of the labels\n",
    "\n",
    "        '''\n",
    "        label = torch.tensor((self.labels[idx]))\n",
    "        image = self.transforms(self.images[idx])\n",
    "        return image, label\n",
    "\n",
    "    def img_transform(image):\n",
    "        '''\n",
    "        Transforms applied to the image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : PIL Image\n",
    "            A list of PIL images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : torch.Tensor\n",
    "            transforms the images with the transform class\n",
    "\n",
    "        '''\n",
    "        image = self.transforms(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset():\n",
    "    '''\n",
    "    Testing Dataset class for pytorch dataloader\n",
    "    '''\n",
    "    def __init__(self, rootpath, filename, transforms=None):\n",
    "        '''\n",
    "        Initiate class variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rootpath : str\n",
    "            The directory of the training dataset\n",
    "        filename : str\n",
    "            Excel file name that contains the ground truth of testing dataset\n",
    "        transforms : <class 'torchvision.transforms.transforms.Compose'>\n",
    "            Transforms that will be applied to the images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        self.rootpath = rootpath\n",
    "        self.images = []  # images\n",
    "        self.labels = []  # corresponding labels\n",
    "        self.transforms = transforms\n",
    "        prefix = self.rootpath + '/'\n",
    "        with open(filename) as f:\n",
    "            gtReader = csv.reader(f, delimiter=';')\n",
    "            next(gtReader)\n",
    "            for row in gtReader:\n",
    "                image = Image.open(prefix + row[0], 'r')\n",
    "                image_arr = np.array(image)\n",
    "                image.close()\n",
    "                image = Image.fromarray(image_arr)\n",
    "                self.images.append(image)  # the 1th column is the filename\n",
    "                self.labels.append(int(row[7]))  # the 8th column is the label\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Length of the class or dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Length of the dataset\n",
    "\n",
    "        '''\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Used for list indexing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : PIL file\n",
    "            Returns PIL file for later transformation\n",
    "        label : torch.tensor\n",
    "            Returns torch.tensor of the labels\n",
    "\n",
    "        '''\n",
    "        label = torch.tensor((self.labels[idx]))\n",
    "        image = self.transforms(self.images[idx])\n",
    "        return image, label\n",
    "\n",
    "    def img_transform(image):\n",
    "        '''\n",
    "        Transforms applied to the image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : PIL Image\n",
    "            A list of PIL images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : torch.Tensor\n",
    "            transforms the images with the transform class\n",
    "\n",
    "        '''\n",
    "        image = self.transforms(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171),\n",
    "                         (0.2672, 0.2564, 0.2629))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset('./GTSRB/Final_Training/Images',\n",
    "                             transforms=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(train_dataset)))\n",
    "# Randomly shuffle the dataset before splitting it into training dataset\n",
    "# and validation dataset\n",
    "random.shuffle(indices)\n",
    "train_sample = SubsetRandomSampler(indices[:35000])\n",
    "val_sample = SubsetRandomSampler(indices[35000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the default batch_size of 1, which can be increased based on the GPU\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, sampler=train_sample)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, sampler=val_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the loaded images along with the label for training.\n",
    "x, y = next(iter(train_loader))\n",
    "print(y)\n",
    "plt.imshow(x.numpy().squeeze(axis=0).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can check the loaded images along with the label for training.\n",
    "x, y = next(iter(val_loader))\n",
    "print(y)\n",
    "plt.imshow(x.numpy().squeeze(axis=0).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loaded training dataset for later uses.\n",
    "torch.save(train_loader, './GTSRB/train_dataloader_32_random_colab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the loaded validation dataset for later uses.\n",
    "torch.save(val_loader, './GTSRB/val_dataloader_32_random_colab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset('./GTSRB/Final_Test/Images', 'GT-final_test.csv',\n",
    "                           transforms=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2 = next(iter(test_loader))\n",
    "print(y2)\n",
    "plt.imshow(x2.numpy().squeeze(axis=0).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_loader, './GTSRB/test_dataloader_32_colab.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
