{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the TODO_Directory_and_Folder_Name\n",
    "# Change the directory to the GTSRB folder that contains the dataset\n",
    "cd '/content/drive/My Drive/TODO_Directory_and_Folder_Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "class TrainDataset():\n",
    "    '''\n",
    "    Training Dataset class for pytorch dataloader\n",
    "    '''\n",
    "    def __init__(self, rootpath, transforms=None):\n",
    "        '''\n",
    "        Initiate class variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rootpath : str\n",
    "            The directory of the training dataset\n",
    "        transforms : <class 'torchvision.transforms.transforms.Compose'>\n",
    "            Transforms that will be applied to the images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        self.rootpath = rootpath\n",
    "        self.images = []  # images\n",
    "        self.labels = []  # corresponding labels\n",
    "        self.transforms = transforms\n",
    "        for c in range(0, 43):\n",
    "            # subdirectory for class\n",
    "            prefix = self.rootpath + '/' + format(c, '05d') + '/'\n",
    "            # annotations file\n",
    "            gtFile = open(prefix + 'GT-' + format(c, '05d') + '.csv')\n",
    "            # csv parser for annotations file\n",
    "            gtReader = csv.reader(gtFile, delimiter=';')\n",
    "            # skip header\n",
    "            next(gtReader)\n",
    "            # loop over all images in current annotations file\n",
    "            for row in gtReader:\n",
    "                image = Image.open(prefix + row[0], 'r')\n",
    "                image_arr = np.array(image)\n",
    "                image.close()\n",
    "                image = Image.fromarray(image_arr)\n",
    "                # the 1th column is the filename\n",
    "                self.images.append(image)\n",
    "                # the 8th column is the label\n",
    "                self.labels.append(int(row[7]))\n",
    "            gtFile.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Length of the class or dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Length of the dataset\n",
    "\n",
    "        '''\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Used for list indexing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            indexs for the list\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : PIL file\n",
    "            Returns PIL file for later transformation\n",
    "        label : torch.tensor\n",
    "            Returns torch.tensor of the labels\n",
    "\n",
    "        '''\n",
    "        label = torch.tensor((self.labels[idx]))\n",
    "        image = self.transforms(self.images[idx])\n",
    "        return image, label\n",
    "\n",
    "    def img_transform(image):\n",
    "        '''\n",
    "        Transforms applied to the image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : PIL Image\n",
    "            A list of PIL images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : torch.Tensor\n",
    "            transforms the images with the transform class\n",
    "\n",
    "        '''\n",
    "        image = self.transforms(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset():\n",
    "    '''\n",
    "    Testing Dataset class for pytorch dataloader\n",
    "    '''\n",
    "    def __init__(self, rootpath, filename, transforms=None):\n",
    "        '''\n",
    "        Initiate class variables\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rootpath : str\n",
    "            The directory of the training dataset\n",
    "        filename : str\n",
    "            Excel file name that contains the ground truth of testing dataset\n",
    "        transforms : <class 'torchvision.transforms.transforms.Compose'>\n",
    "            Transforms that will be applied to the images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        self.rootpath = rootpath\n",
    "        self.images = []  # images\n",
    "        self.labels = []  # corresponding labels\n",
    "        self.transforms = transforms\n",
    "        prefix = self.rootpath + '/'\n",
    "        with open(filename) as f:\n",
    "            gtReader = csv.reader(f, delimiter=';')\n",
    "            next(gtReader)\n",
    "            for row in gtReader:\n",
    "                image = Image.open(prefix + row[0], 'r')\n",
    "                image_arr = np.array(image)\n",
    "                image.close()\n",
    "                image = Image.fromarray(image_arr)\n",
    "                self.images.append(image)  # the 1th column is the filename\n",
    "                self.labels.append(int(row[7]))  # the 8th column is the label\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Length of the class or dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Length of the dataset\n",
    "\n",
    "        '''\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Used for list indexing\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : TYPE\n",
    "            DESCRIPTION.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : PIL file\n",
    "            Returns PIL file for later transformation\n",
    "        label : torch.tensor\n",
    "            Returns torch.tensor of the labels\n",
    "\n",
    "        '''\n",
    "        label = torch.tensor((self.labels[idx]))\n",
    "        image = self.transforms(self.images[idx])\n",
    "        return image, label\n",
    "\n",
    "    def img_transform(image):\n",
    "        '''\n",
    "        Transforms applied to the image\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : PIL Image\n",
    "            A list of PIL images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        image : torch.Tensor\n",
    "            transforms the images with the transform class\n",
    "\n",
    "        '''\n",
    "        image = self.transforms(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.load('./GTSRB/train_dataloader_32_random_colab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.load('./GTSRB/val_dataloader_32_random_colab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.load('./GTSRB/test_dataloader_32_colab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Neural network models used for this challenge.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initiate class variables\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250*2*2, 350)\n",
    "        self.fc2 = nn.Linear(350, 43)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Forward function from input to output\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.tensor\n",
    "            torch.tensors or the images in the dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        TYPE torch.tensor\n",
    "            predicted labels\n",
    "\n",
    "        '''\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = self.bn1(x)\n",
    "        x = self.drop(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = self.bn2(x)\n",
    "        x = self.drop(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = self.bn3(x)\n",
    "        x = self.drop(x)\n",
    "        x = x.view(-1, 250*2*2)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_boole = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print True if using GPU\n",
    "gpu_boole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "if gpu_boole:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Adam as the optimizer and CrossEntropyLoss for loss metric\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss_metric = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(true_y, pred_y):\n",
    "    '''\n",
    "    Calculate the accuracy between the grouth truth and prediced label\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_y : torch.tensor\n",
    "        Grouth truth label for the image\n",
    "    pred_y : torch.tensor\n",
    "        Predicted label for the image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : float\n",
    "        Accuracy of the predicted label compared with the ground truth\n",
    "\n",
    "    '''\n",
    "    true_prediction_num = 0\n",
    "    for i, py in enumerate(pred_y):\n",
    "        idx = torch.argmax(py)\n",
    "        if idx == true_y[i]:\n",
    "            true_prediction_num += 1\n",
    "    accuracy = true_prediction_num / len(pred_y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(net, loader, verbose=1):\n",
    "    '''\n",
    "    Evaluation of the model with loss and accuracy returned\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : Model class\n",
    "        Class of the model or neural network\n",
    "    loader : torch.utils.data.dataloader.DataLoader\n",
    "        The pytorch dataloader\n",
    "    verbose :\n",
    "        The default is 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The accuracy of the model to predict the loader\n",
    "    loss_avg : float\n",
    "        The average loss for predicting the loader\n",
    "\n",
    "    '''\n",
    "    loss_sum = []\n",
    "    acc = []\n",
    "    for x, labels in loader:\n",
    "        if gpu_boole:\n",
    "            x, labels = x.cuda(), labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = net(x)\n",
    "    predicted = outputs.data.round()\n",
    "    loss = loss_metric(outputs, labels)\n",
    "    loss_sum.append(loss.cpu().data.numpy().item())\n",
    "    loss_avg = np.mean(loss_sum)\n",
    "    acc.append(calc_accuracy(labels, predicted))\n",
    "    if verbose:\n",
    "        print('Accuracy: %f %%' % (100.0 * np.mean(acc)))\n",
    "        print('Loss: %f' % loss_avg)\n",
    "    return 100 * np.mean(acc), loss_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initializing network weights:\n",
    "def weights_init(m):\n",
    "    '''\n",
    "    Weight initiation of the model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    m : Model class\n",
    "        Class of the model or neural network\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "net.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# number of epochs to train for:\n",
    "epochs = 150  # This number can be changed\n",
    "# defining batch train loss recording arrays for later visualization/plotting:\n",
    "loss_batch_store = []\n",
    "loss_batch = []\n",
    "acc_test = []\n",
    "acc_val = []\n",
    "acc_train = []\n",
    "loss_val = []\n",
    "loss_train = []\n",
    "print(\"Starting Training\")\n",
    "# training loop:\n",
    "for epoch in range(epochs):\n",
    "    time1 = time.time()  # timekeeping\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        if gpu_boole:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "    # Loss calculation and gradient update:\n",
    "    if i > 0 or epoch > 0:\n",
    "        optimizer.zero_grad()\n",
    "    outputs = net(x)\n",
    "    loss = loss_metric(outputs, y.long())\n",
    "    loss.backward()\n",
    "    # Create a batch store for all losses\n",
    "    if i > 0 or epoch > 0:\n",
    "        loss_batch_store.append(loss.cpu().data.numpy().item())\n",
    "    # Performing update:\n",
    "    optimizer.step()\n",
    "    loss_batch.append(np.mean(loss_batch_store))\n",
    "    print(\"Epoch\", epoch+1, ':')\n",
    "    print(\"The accuracy and loss for training, validation, \"\n",
    "          \"and testing respectively are\")\n",
    "    train_perc, train_loss = eval(net, train_loader, gpu_boole)\n",
    "    val_perc, val_loss = eval(net, val_loader, gpu_boole)\n",
    "    # test_perc, test_loss, test_predicted = eval(net, test_loader, gpu_boole)\n",
    "    acc_val.append(val_perc)\n",
    "    acc_train.append(train_perc)\n",
    "    # acc_test.append(test_perc)\n",
    "    loss_val.append(val_loss)\n",
    "    loss_train.append(train_loss)\n",
    "    time2 = time.time()  # timekeeping\n",
    "    print('Elapsed time for epoch:', time2 - time1, 's')\n",
    "    print('ETA of completion:', (time2 - time1)*(epochs - epoch - 1)/60,\n",
    "          'minutes')\n",
    "    print()\n",
    "# Plotting batch-wise train loss curve:\n",
    "plt.plot(loss_batch, label='train_loss', color='blue')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Sample-wise Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plotting batch-wise validation loss curve:\n",
    "plt.plot(loss_val, label='Validation_loss', color='blue')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Sample-wise Loss At Last minibatch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plotting batch-wise training accuracy curve:\n",
    "plt.plot(acc_train, label='Training Accuracy', color='red')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Training accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Plotting batch-wise validation accuracy curve:\n",
    "plt.plot(acc_val, label='Validation Accuracy', color='red')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc, test_loss = eval(net, test_loader, gpu_boole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The accuracy of the trained model on the test dataset is',\n",
    "      test_perc, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
